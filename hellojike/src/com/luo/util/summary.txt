
版本
lucene          6.0.0
elasticsearch
luke            6.0.0   es gui 工具
    https://github.com/DmitryKey/luke/releases/download/luke-6.0.0/luke-6.0.0-luke-release.zip
IK分词器
    http://code.google.com/archive/p/ik-analyzer/downloads
    https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/ik-analyzer/IK%20Analyzer%202012_u6_source.rar
Tika    1.13    用于文件类型检测以及文件内容提取
    https://tika.apache.org/download.html
    java -jar tika-app-1.13.jar -g
Bigdesk 集群监控工具
    http://github.com/hlstudio/bigdesk.git

StopAnalyzer    停用词分词器
    通过停用词进行分词
StandardAnalyzer 标准分词器
    通过空格和符号进行分割

TextField   会索引，会词条化，不会保存词向量。
    词向量是指TermVectors,记录每篇文档每个字段每个词的词频，位置，字符偏移量，playload信息
StringField 会索引，不会词条化，不会保存词向量。
DocValuesField  当lucene需要聚合或者排序时，会遍历所有字段并进行内部操作。
    DocValuesField会在索引的基础上，建立一个y已经排序好的Document->Field/Value 的映射列表
    减轻排序、分组时对内存的依赖。当然也会占用一部分空间。
IntPoint    索引int类型的值，只是做快速过滤。如果需要显示出来需要另外一个字段储存 ???有点奇怪
            这是因为IntPoint类型的字段，会将元素添加到PostingList中，如果需要储存需要单独添加一个StoreField类型字段



5 创建索引
put blogs
--创建索引默认5个分片,1个副本。分片数量指定后不能修改，而副本可以
put blogs
{
    "settings":{
        "number_of_shards":3,
        "number_of_replicas":1
    }
}
--更改副本数量,以及读写权限
put blogs/_settings
{
    "number_of_replicas":2,
    "blocks.read_only":true,    //设置当前索引只允许读,不允许更新
    "blocks.read":true,         //设置当前索引不可读
    "blocks.write":true         //设置当前索引不可写
}
--查看索引
get blogs/_settings
get blogs,blog/_settings
get _all/_settings
--删除索引
delete blog
--打开,关闭索引.关闭的索引几乎不占用资源
post blogs/_close
post blogs/_open
post blog,blogs/_close
post _all/_close
----操作不存在的索引会报错 测试发现没有生效?
post blogg/_close?ignore_unavailable=true
--复制索引
post _reindex
{
    "source":{"index":"blog"},
    "dest":{"index":"blog_new"}
}
----复制索引时,使用type和query来限制文档
post _reindex
{
    "sourcce":{
        "index":"blog",
        "type":"article",
        "query":{
            "term":{"title":"git"}
        }
    },
    "desc":{
        "index":"blog_new"
    }
}
----收缩索引.能将索引分片缩小
----将索引分片收缩到一个节点上,同时保持该索引只读
put blogsss/_settings
{
    "index.routing.allocation.require._name":"shrink_node_name",
    "index.blocks.write":true
}
----配置新索引的配置
post blogsss/_shrink/blogsss_new
{
    "settings":{
        "number_of_shards":3,
        "number_of_replicas":1,
        "index.codec":"best_compression"
    },
    "aliases":{
        "my_search_indices":{}
    }
}
--索引别名
----添加别名 actions 可以输入多个
post /_aliases
{
    "actions":[
        "add":{
            "index":"test1",
            "alias":"alias1"
        }
    ]
}
----移除别名
post /_aliases
{
    "actions":[
        "remove":{
            "index":"test1",
            "alias":"alias1"
        }
    ]
}
--查看别名
get /test/_aliases
--新建文档 指定id
put /blog/article/1
{
    "id":1,
    "title":"git简介",
    "posttime":"2017-01-02",
    "content":"Git是一款开源,免费的分布式版本控制软件"
}
--新建文档 不指定id
post /blog/article
{
    "id":1,
    "title":"git简介",
    "posttime":"2017-01-02",
    "content":"Git是一款开源,免费的分布式版本控制软件"
}
--获取文档 found表示是否找到,_source表示文档内容
get /blog/article/1
--判断是否存在 返回200-ok或者404
head /blog/article/1
--获取多个文档 mget api
get _mget
{
    "docs":[
        {
            "_index":"blog",
            "_type":"article",
            "_id":"1"
        },
        {
            "_index":"blogsss",
            "_id":"11"
        }
    ]
}
--更新文档
----先创建一条文档
put test/type1/1
{
    "counter":1,
    "tags":["red"]
}
----update api修改
----ctx是脚本语言的一个执行对象 .painless是es内置的脚本语言
----ctx还可以获取 _index,_type,_id,_version,_routing,_parent等
----给counter加四
post /test/type1/1/_update
{
    "script":{
        "inline":"ctx._source.counter+=params.count",
        "lang":"painless",
        "params":{
            "count":4
        }
    }
}
----给tags数组添加元素
post /test/type1/1/_update
{
    "script":{
        "inline":"ctx._source.tags.add(params.tag)",
        "lang":"painless",
        "params":{
            "tag":"blue"
        }
    }
}
----给文档添加一个属性
post /test/type1/1/_update
{
    "script":{
        "inline":"ctx._source.name=\"luoluoluo\""
    }
}
----给文档删除一个属性
post /test/type1/1/_update
{
    "script":{
        "inline":"ctx._source.remove(\"name\")"
    }
}
----删除tags数组中含有red的文档
----ctx.op 表示操作类型,delete表示删除,none表示不操作
post /test/type1/1/_update
{
	"script": {
		"inline": "if(ctx._source.tags.contains(params.tag)) {ctx.op = \"delete\"}else {ctx.op = \"none\"}",
		"lang": "painless",
		"params": {
			"tag": "red"
		}
	}
}
----更新还有一个 upsert,表示当存在则更新,不存在则新建一个文档
post /test/type1/1/_update
{
    "script":{
        "inline":"ctx._source.counter+=params.counter",
        "lang":"painless",
        "params":{
            "counter":4
        }
    },
    "upsert":{
        "counter":2
    }
}
----查询更新 使用update_by_query api
post /blog/article/_update_by_query
{
    "script":{
        "inline":"ctx._source.category+=params.category",
        "lang":"painless",
        "params":{
            "category":"git"
        }
    },
    "query":{
        "term":{
            "title":"git"
        }
    }
}
----删除文档
delete /blog/article/1
----如果索引文档添加了路由,删除时也可以添加路由
----指定了路由,那么储存的分片将会根据路由确定.对于该文档的查询,没有指定路由将无法查询到
delete /blog/article/1?routing=user123
----查询删除 使用 _delete_by_query
post /blog/article/_delete_by_query
{
    "query":{
        "term":{
            "title":"java"
        }
    }
}
----如果需要删除一个索引下的所有文档
post /blog/article/_delete_by_query
{
    "query":{
        "match_all":{}
    }
}
----批量操作 json文件每一行内容都需要换行
----注意一次提交的数据量.整个批量操作的内容会被加载到请求节点的内存中
----一般在5m到15m之间
curl -XPOST 'localhost:9200/website/_bulk?pretty' --data-binary @data.json
{"delete":{"_index":"website","_type":"blog","_id":123}}
{"create":{"_index":"website","_type":"blog","_id":123}}
{"title":"my first blog here"}
{"index":{"_index":"website","_type":"blog"}}
{"title":"my second blog here"}
{"update":{"_index":"website","_type":"blog","_id":123}}
{"doc":{"title":"my update blog post"}}
----版本控制
----获取某个版本的文档
get /website/blog/1?version=1
----指定当文档版本为多少时,才会进行更新
put /website/blog/123?version=2
{"title":"xxxx"}
----指定为外部版本,只有当外部指定的版本比原来版本高才会进行更新
put /website/blog/123?version=10&version_type=external
----路由机制,默认使用id作为路由值
shard=hash(routing) % number_of_primary_shard


--动态映射
json类型      es类型
null         不会被添加
true/false   boolean
浮点          float
数字          long
json对象      object类型
数组          由数组第一个元素决定
字符串         可能有date类型(开启日期检测),double,long,text类型,keyword类型
----测试动态映射
put /books
get /books/_mapping
----此时id被映射成long,publish_date被映射成date,name被映射成text,keyword
put /books/it/1
{
    "id":1,
    "publish_date":"2017-06-01",
    "name":"master ElasticSearch"
}
----在mapping中可以通过 dynamic 配置动态属性.默认为true,表示自动添加字段.false忽略新字段,strict严格模式,发现新字段抛出错误
put /books/
{
    "mappings":{
        "it":{
            "dynamic":"strict",
            "properties":{
                "title":{
                    "type":"text"
                },
                "publish_date":{
                    "type":"date"
                }
            }
        }
    }
}
----日期检测关闭 当新的字段第一次出现的值为时间字符串时,该字段会被配置成日期类型.而第二条文档如果该字段不是日期字符串则会抛错
----在index的某个type上将date_detection关闭
put /books
{
    "mappings":{
        "it":{
            "date_detection":false
        }
    }
}
----静态映射
put schools
{
    "mappings":{
        "user":{
            "_all":{"enabled":false},
            "properties":{
                "title":{"type":"text"},
                "name":{"type":"text"},
                "age":{"type":"integer"}
            }
        },
        "blogpost":{
            "_all":{"enabled":true},
            "properties":{
                "title":{"type":"text"},
                "body":{"type":"text"},
                "user_id":{"type":"keyword"},
                "create":{
                    "type":"date",
                    "format":"strict_date_optional_time||epoch_millis"
                }
            }
        }
    }
}
----字段类型
        string  es5.x后抛弃此类型,由text和keyword代替
        text    可以被全文搜索,文本会被分词器分成一个个词项然后索引.text不用于排序,很少用于聚合(termsAggregation除外)
        keyword 不会对内容进行分词,只能被精确搜索到
        数字类型 byte,short,integer,long,float,double,half_float,scaled_float
            对于flaot,half_float,scaled_float来说, -0.0和+0.0是不同的.使用term查询-0.0不会匹配+0.0
            scaled_float 会将值保存为整数,因为省空间?
        date    json没有date类型,所以在es中的日期有以下几种类型.
            格式化的字符串 如 2015-01-01 或者 2015/01/01 12:12:12
            代表 milliseconds-since-the-epoch 的长整数
            代表 seconds-since-the-epoch 的长整数.
            es内部会将日期格式化为UTC,并储存为 milliseconds-since-the-epoch 的长整数.日期格式可以定义,没有自定义则为 strict_date_optional_time||epoch_millis
        boolean 值为 true,false,"true","false",数字
        binary  接受base64的编码,默认不存储?(为啥我能查询到),不能被搜索(这个确实)
        array   默认使用第一个元素的类型,一个数组中的类型必须一致.在文档中使用array类型不需要提前配置.默认支持
        object  json文档中保存文档.写入es后,文档会被索引成简单的扁平key-value结构.
        nested  为了避免对象数组之间的关系被消除,进而出现 nested, 这种类型能保证每个对象的独立性
        range   范围类型
        token_count 用于统计字符串分词后的词项个数
----数字类型配置
put number_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "number_of_types":{"type":"integer"},
                "time_of_types":{"type":"float"},
                "price":{
                    "type":"scaled_float",
                    "scaling_factor":100
                }
            }
        }
    }
}
----binary类型
put binary_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "name":{"type":"text"},
                "blob":{"type":"binary"}
            }
        }
    }
}
post binary_index/my_type
{
    "name":"hello",
    "blob":"aGVsbG93b3JsZA=="
}
----array类型,array的查询
post binary_index/my_type
{
    "name":"hello",
    "blob":"aGVsbG93b3JsZA==",
    "messages":["es","java"],
    "lists":[
        {"name":"prog_list"},
        {"name":"cool_list"}
    ]
}
get /binary_index
{
    "query":{
        "match":{
            "lists.name":"list"
        }
    }
}
----object mapping
put object_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "region":{"type":"keyword"},
                "manager":{
                    "properties":{
                        "age":{"type":"integer"},
                        "name":{"type":"text"}
                    }
                }
            }
        }
    }
}
----但是由于object只是将对象数组偏平化,转成简单列表.所以有时候会有问题
put object/index
{
    "groups":"fans",
    "user":[
        {
            "first":"john",
            "last":"smith"
        },{
            "first":"alice",
            "last":"white"
        }
    ]
}
----会被储存成下边的形式,对象数组的对象内容将会失去联系
{
    "groups":"fans",
    "user.first":["john","alice"],
    "user.last":["smith","white"]
}
----以下查询会被搜索到
get /object_index/my_type/_search
{
    "query":{
        "bool":{
            "must":[
                {"match":{"user.first":"alice"}},
                {"match":{"user.last":"smith"}}
            ]
        }
    }
}
----将上述对象修改成 nested .在进行搜索等就搜索不到了
put object_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "user":{
                    "type":"nested"
                }
            }
        }
    }
}
----范围类型
put range_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "expected_attendees":{
                    "type":"integer_range"
                },
                "time_frame":{
                    "type":"date_range",
                    "format":"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
                }
            }
        }
    }
}
----写入范围
put range_index/my_type/1
{
    "expected_attendees":{
        "gte":10,
        "lte":20
    },
    "time_frame":{
        "gte":"2015-02-02 12:00:00",
        "lte":"2015-09-09"
    }
}
----token_count
put token_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "name":{
                    "type":"text",
                    "fields":{
                        "length":{
                            "type":"token_count",
                            "analyzer":"standard"
                        }
                    }
                }
            }
        }
    }
}
----放入数据 发现并没有储存 name.length字段
put token_index/my_type
{
    "name":"john smith"
}
put token_index/my_type
{
    "name":"richals tom jerry"
}
----搜索 token_count.虽然没有储存token_count字段,但是却可以搜索到
get token_index/my_type
{
    "query":{
        "term":{
            "name.length":3
        }
    }
}

--元字段
---- _index,_type,_id,_uid (_uid={type}#{id})
---- _source,_size
---- _all,_field_names
    _all 字段是将所有字段全部拼装在一起,字段之间使用空格隔开.会被解析和索引,但是不会储存
    _field_names 将所有不为空的字段拼装在一起,会储存??? 通常用于 exists 查询
---- _parent,_routing
---- 按照 _index 搜索,分组,排序
---- 页可以替换成 _type
get range_index,object_index/_search
{
    "query":{
        "terms":{
            "_index":["range_index","object_index"]
        }
    },
    "aggs":{
        "indices":{
            "terms":{
                "field":"_index",
                "size":10
            }
        }
    },
    "sort":[
        {"_index":{"order":"asc"}}
    ]
}
----通过 _all 搜索
get object_index/_search
{
    "query":{
        "match":{
            "_all":"git"
        }
    }
}
----通过 _field_names 搜索每个字段不为空的文档
get object_index/_search
{
    "query":{
        "terms":{
            "_field_names":["name"]
        }
    }
}
----配置必须指定路由
put route_index
{
    "mappings":{
        "my_type":{
            "_routint":{
                "required":true
            }
        }
    }
}
--映射参数
----analyzer 分词器
put analyzer_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "content":{
                    "type":"text",
                    "analyzer":"ik_max_word"
                }
            }
        }
    }
}

--映射参数
----analyzer 指定字段的分词器,对索引和查询都有效.
put analyzer_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "content":{
                    "type":"text",
                    "analyzer":"ik_max_word"
                }
            }
        }
    }
}
---- search_analyzer 大多数情况索引和搜索应该指定相同的分词器.确保query解析后和索引的词项是一致的
---- edge_gram 和 ngram 是es自带的两个分词器.
---- edge_gram 会从首字开始,按照步长,逐字符分词,直到结尾. 而 ngram 会按照顺序从各个位置开始按照步长,逐字符分词,直到词尾
---- 具体应用 需要前缀匹配的话, edge_gram是最佳选择,而需要文中任意位置匹配 ngram 更为适合
---- TODO 算了还不是很懂这一块
put analyzer_index
{
    "settings":{
        "analysis":{
            "filter":{
                "autocomplete_filter":{
                    "type":"edge_ngram",
                    "min_gram":1,
                    "max_gram":20
                }
            },
            "analyzer":{
                "autocomplete":{
                    "type":"custom",
                    "tokenizer":"standard",
                    "filter":[
                        "lowercase","autocomplete_filter"
                    ]
                }
            }
        }
    },
    "mappings":{
        "my_type":{
            "properties":{
                "text":{
                    "type":"text",
                    "analyzer":"autocomplete",
                    "search_analyzer":"standard"
                }
            }
        }
    }
}
----写入 倒排索引会有 q qu qui quic quick b br bro brow brown f fo fox
put /analyzer_index/my_type/1
{
    "text":"Quick Brown Fox"
}
---- normalizer 用于解析前的标准化配置,比如将所有字符转为小写 下边例子中foo字段在解析前使用自定义的normalizer把字符串标准化为小写
put /analyzer_index
{
    "settings":{
        "analysis":{
            "normalizer":{
                "my_normalizer":{
                    "type":"custom",
                    "char_filter":[],
                    "filter":[
                        "lowercase","asciifolding"
                    ]
                }
            }

        }
    },
    "mappings":{
        "my_type":{
            "properties":{
                "foo":{
                    "type":"keyword",
                    "normalizer":"my_normalizer"

                }
            }
        }
    }
}
---- boost 设置权重.比如设置关键字在title字段权重是其他子弹的两倍
put /analyzer_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "title":{
                    "type":"text",
                    "boost":2
                },
                "context":{
                    "type":"text"
                }
            }
        }
    }
}
---- 在查询时也可以指定权重
put /analyzer_index
{
    "query":{
        "match":{
            "title":{
                "query":"quick brown fox",
                "boost":2
            }
        }
    }
}
---- coerce 属性用于清除脏数据.默认为true.比如整型字段有可能被写为字符串5 5.0 或者"5" .设置 coerce为false的字段,如果类型不正确则会抛错
put /analyzer_index
{
    "mappings":{
        "my_type":{
            "properties":{
                "number_one":{
                    "type":"integer"
                },
                "number_two":{
                    "type":"integer",
                    "coerce":false
                }
            }
        }
    }
}

--搜索
----造数据
PUT books
{
  "settings": {
    "number_of_replicas": 1,
    "number_of_shards": 3
  },
  "mappings": {
    "IT": {
      "properties": {
        "id": {
          "type": "long"
        },
        "title": {
          "type": "text",
          "analyzer": "ik_max_word"
        },
        "language": {
          "type": "keyword"
        },
        "author": {
          "type": "keyword"
        },
        "price": {
          "type": "double"
        },
        "year": {
          "type": "date",
          "format": "yyyy-MM-dd"
        },
        "description": {
          "type": "text",
          "analyzer": "ik_max_word"
        }
      }
    }
  }
}
{"index":{ "_index": "books", "_type": "IT", "_id": "1" }}
{"id":"1","title":"Java编程思想","language":"java","author":"Bruce Eckel","price":70.20,"publish_time":"2007-10-01","description":"Java学习必读经典,殿堂级著作！赢得了全球程序员的广泛赞誉。"}
{"index":{ "_index": "books", "_type": "IT", "_id": "2" }}
{"id":"2","title":"Java程序性能优化","language":"java","author":"葛一鸣","price":46.50,"publish_time":"2012-08-01","description":"让你的Java程序更快、更稳定。深入剖析软件设计层面、代码层面、JVM虚拟机层面的优化方法"}
{"index":{ "_index": "books", "_type": "IT", "_id": "3" }}
{"id":"3","title":"Python科学计算","language":"python","author":"张若愚","price":81.40,"publish_time":"2016-05-01","description":"零基础学python,光盘中作者独家整合开发winPython运行环境，涵盖了Python各个扩展库"}
{"index":{ "_index": "books", "_type": "IT", "_id": "4" }}
{"id":"4","title":"Python基础教程","language":"python","author":"Helant","price":54.50,"publish_time":"2014-03-01","description":"经典的Python入门教程，层次鲜明，结构严谨，内容翔实"}
{"index":{ "_index": "books", "_type": "IT", "_id": "5" }}
{"id":"5","title":"JavaScript高级程序设计","language":"javascript","author":"Nicholas C. Zakas","price":66.40,"publish_time":"2012-10-01","description":"JavaScript技术经典名著"}
curl -XPOST "http://173.82.48.12:9200/_bulk?pretty" --data-binary @data.json

----词项查询 词项不可以再被分词
get books/_search
{
    "query":{
        "term":{
            "title":"思想"
        }
    }
}
---- 分页处理
---- 只需要返回指定的字段
---- 返回version
---- min_score 最小评分
---- highlight 高亮处理
get books/_search
{
    "from":0,
    "size":100,
    "_source":["title","author","title"],
    "version":true,
    "min_score":0.6,
    "query":{
        "term":{
            "title":"思想"
        }
    },
    "highlight":{
        "fields":{
            "title":{}
        }
    }
}
---- match query 全文查询 会将查询内容分词
get books/_search
{
    "query":{
        "match":{
            "title":{
                "query":"java编程思想",
                "operator":"or"
            }
        }
    }
}
---- match_phrase query 该查询会将query内容分词,同时必须按照分词后的顺序依次全部出现在文档中
get books/_search
{
    "query":{
        "match_phrase":{
            "title":"java编程思想"
        }
    }
}
---- match_phrase_prefix query 跟 match_phrase类似,加了可以前缀匹配
get books/_search
{
    "query":{
        "match_phrase_prefix":{
            "title":"java编程思*"
        }
    }
}
---- multi_match query 这个是 match query 的升级版本,用于搜索多个字段.
---- 支持通配符,可以设置搜索字段的权重.比如title出现的权重时description的三倍
get books/_search
{
    "query":{
        "multi_match":{
            "query":"java",
            "fields":["title^3","description","*_data"]
        }
    }
}
---- common_terms query 是一种在不牺牲性能的前提下,代替停用词提升搜索准确性和召回率的方案
---- 一般搜索比如 the brown fox ,query 会被解析成三个term(the ,brown,fox).很明显 the 的 重要
---- 程度没有其他两个词重要.传统解决方案是将停用词过滤处理,去掉停用词之后可以减小索引大小
---- 虽然停用词对评分影响不大,但是当停用词在query中有重要意义的时候.
---- 去掉停用词就无法辨别出类似 happy ,not happy之类的区别
---- common_terms 提供一种解决方案,它把query分词后的term分为重要词汇(低频)和不重要词汇(高频)
---- 在搜索时首先用根据重要词汇搜索并计算评分,然后在第二次搜索对评分比较小的高频词汇
---- 高频词汇不计算所有文档评分,而是只计算第一次搜索出来的文档的评分
---- 如果只有包含高频词汇,那么会通过and连接符搜索所有词项
---- 高频还是低频通过 cutoff_frequency 来设置阈值
---- 低频词汇之间的连接符为 low_freq_operator,高频词汇之间通过 high_freq_operator
---- 设置低频词汇必须出现,使用如下查询
get books/_search
{
    "query":{
        "common":{
            "body":{
                "query":"nelly the elephant as a cat",
                "cutoff_frequency":0.01,
                "low_freq_operator":"and"
            }
        }
    }
}
---- 上述搜索等价与
get books/_search
{
    "query":{
        "bool":{
            "must":[
                {"term":{"body":"nelly"}},
                {"term":{"body":"elephant"}},
                {"term":{"body":"cat"}}
            ],
            "should":[
                {"term":{"body":"the"}},
                {"term":{"body":"as"}},
                {"term":{"body":"a"}}
            ]
        }
    }
}
---- simple_query_string
get books/_search
{
    "query":{
        "simple_query_string":{
            "query":"\"fried eggs\" + (eggplant | potota) -frittata",
            "analyzer":"snowball",
            "fields":["body^5","_all"],
            "default_operator":"and"
        }
    }
}
---- terms query 词项查询
get books/_search
{
    "query":{
        "terms":{
            "title":["java","python"]
        }
    }
}
---- range query
get books/_search
{
    "query":{
        "range":{
            "price":{
                "gt":50,
                "lt":100
            }
        }
    }
}
get books/_search
{
    "query":{
        "range":{
            "publish_time":{
                "gt":"2007/08/08",
                "lt":"2020/01/01",
                "format":"yyyy/mm/dd"
            }
        }
    }
}
---- exists query 当字段不为空(null),或者列表含有一个非空值就可以查询到
get　books/_search
{
    "query":{
        "exists":{
            "field":"publish_time"
        }
    }
}
---- prefix query 能查询到包含以固定字符为前缀的关键字的文档
get books/_search
{
    "query":{
        "prefix":{
            "description":"win"
        }
    }
}
---- wildcard query
get books/_search
{
    "query":{
        "wildcard":{
            "author":"张*"
        }
    }
}
---- regexp query 以正则表达式
get books/_search
{
    "query":{
        "regexp":{
            "poscode":"W[0-9].+"
        }
    }
}
---- fuzzy query 模糊查询
get books/_search
{
    "query":{
        "fuzzy":{
            "title":"pythno"
        }
    }
}
--- type query 用于查询某个类型的文档
get books/_search
{
    "query":{
        "type":{
            "value":"IT"
        }
    }
}
---- ids query 用户查询某些id的文档,可以指定type
get books/_search
{
    "query":{
        "ids":{
            "type":"IT",
            "values":[1,3,4]
        }
    }
}
---- constant_score query 可以包装一个其他类型的查询,然后匹配过滤器的查询条件且具有相同的评分
get books/_search
{
    "query":{
        "constant_score":{
            "filter":{
                "term":{
                    "title":"java"
                }
            },
            "boost":1.2
        }
    }
}
---- bool query
---- must 文档必须匹配must下边的条件
---- must_not 文档必须不匹配must_not下的条件
---- should 文档可以匹配should下的条件,也可以不匹配should下的条件.相当于逻辑运算 or
---- filter 跟must类似,但是这仅起到过滤条件的作用.不参与评分
---- 查询关键字包含 java,描述可以包含或者不包含虚拟机,并且价格不大于70的文档
get books/_search
{
    "query":{
        "bool":{
            "minimum_should_match":1,
            "must":{
                "match":{
                    "title":"java"
                }
            },
            "should":{
                "match":{
                    "description":"虚拟机"
                }
            },
            "must_not":{
                "range":{
                    "price":{
                        "gt":70
                    }
                }
            }
        }
    }
}
--- TODO dis_max query 该查询支持多并发查询,可返回任意查询条件子句匹配的任何文档.  不是很懂
get books/_search
{
    "query":{
        "dis_max":{
            "tie_breaker":0.7,
            "boost":1.2,
            "queries":[
                {
                    "term":{"title":"java"}
                },{
                    "term":{"title":"python"}
                }
            ]
        }
    }
}
---- function_score query 通过评分函数得到的评分很高时,可以使用过滤器+自定义评分函数来取代传统评分方式
---- 以下会返回books索引的所有文档,最大评分为5,每个文档评分随机生成,权重的计算模式为相乘
get books/_search
{
    "query":{
        "function_score":{
            "query":{"match_all":{}},
            "boost":5,
            "random_score":{},
            "boost_mode":"multiply"
        }
    }
}
---- 使用自定义脚本评分,原来分数的十分之一,然后开方  为什么还变大了???
get books/_search
{
    "query":{
        "function_score":{
            "query":{"match":{"title":"java"}},
            "script_score":{
                "script":{
                    "inline":"Math.sqrt(doc['price'].value/10)"
                }
            }
        }
    }
}
---- boosting 查询. boosting包含positive,negative,negative_boost三部分.
---- boosting query会将两个查询封装在一起,并降低其中一个[评分
---- positive评分保持不变,negative评分降低,negative_boost为抑制系数
get books/_search
{
    "query":{
        "boosting":{
            "positive":{
                "match":{"title":"python"}
            },
            "negative":{
                "range":{
                    "publish_time":{
                        "lte":"2015-01-01"
                    }
                }
            },
            "negative_boost":0.2
        }
    }
}
---- indices query 用于在多个索引查询.允许指定一个索引列表和内部查询. indices query包含query和no_match_query两部分.query用于搜索指定索引列表的文档.
---- no_match_query 用于在指定索引列表之外的搜索
---- 以下在books,bookss索引搜索title包含关键字javascript,在其他索引搜索title包含baskball的文档
get books/_search
{
    "query":{
        "indices":{
            "indices":["books","bookss"],
            "query":{
                "match":{"title":"javascript"}
            },
            "no_match_query":{
                "term":{
                    "title":"baskball"
                }
            }
        }
    }
}
-- 嵌套查询,es没有类似于sql join的功能
---- TODO nested query 没看懂
---- has_child query
---- 建立父子关系 branch为父级,employee为子级
put company
{
    "mappings":{
        "branch":{},
        "employee":{"_parent":{"type":"branch"}}
    }
}
---- 写入 branch 数据
curl -XPOST "http://173.82.48.12:9200/company/branch/_bulk?pretty" --data-binary @data.json
post company/branch/_bulk
{"index":{"_id":"london"}}
{"name":"London Westminster","city":"London","country":"UK"}
{"index":{"_id":"liverpool"}}
{"name":"Liverpool Central","city":"Liverpool","country":"UK"}
{"index":{"_id":"paris"}}
{"name":"Champs Elysees","city":"Paris","country":"France"}
---- 写入 employee 数据
curl -XPOST "http://173.82.48.12:9200/company/employee/_bulk?pretty" --data-binary @data.json
post company/employee/_bulk
{"index":{"_id":1,"parent":"london"}}
{"name":"Alice Smith","dob":"1970-10-24","hobby":"hiking"}
{"index":{"_id":2,"parent":"london"}}
{"name":"Marks Thomas","dob":"1982-05-16","hobby":"diving"}
{"index":{"_id":3,"parent":"liverpool"}}
{"name":"Barry Smith","dob":"1979-04-01","hobby":"hiking"}
{"index":{"_id":4,"parent":"paris"}}
{"name":"Adrien Grand","dob":"1987-05-11","hobby":"horses"}
---- 通过子查询查询父文档记录,需要使用 has_child
---- 查询1980年后出现员工所在的分支机构
get company/branch/_search
{
    "query":{
        "has_child":{
            "type":"employee",
            "query":{
                "range":{
                    "dob":{
                        "gte":"1980-01-01"
                    }
                }
            }
        }
    }
}
---- 搜索哪些机构员工名为 Alice Smith.因为使用 match 查询,query会被分词,
---- 指定 score_mode 为max后才有评分,没有的话都是 1???
---- 指定 min_children 拥有子文档的最小个数,比如查询至少拥有两个子文档的文档
get company/branch/_search
{
    "query":{
        "has_child":{
            "type":"employee",
            "query":{
                "match":{
                    "name":"Alice Smith"
                }
            },
            "score_mode":"max",
            "min_children":2
        }
    }
}
---- 跟 has_child类似,在子文档中可以使用 has_parent 查询
get company/employee/_search
{
    "query":{
        "has_parent":{
            "parent_type":"branch",
            "query":{
                "match":{"country":"UK"}
            }
        }
    }
}

---- TODO 位置查询

--特殊查询
---- more_like_this query 用来查询类似文本推荐的场景
---- fields 是需要匹配的字段,默认是 _all
---- like 是需要匹配的内容
---- min_term_freq 是文档中词项的频率,默认是2
---- max_query_terms query能包含的最大词项数,默认时25
---- 还有很多参数
get books/_search
{
    "query":{
        "more_like_this":{
            "fields":["title","description"],
            "like":"java virtual machine",
            "min_term_freq":1,
            "max_query_terms":12
        }
    }
}
---- script query 能通过脚本查询
get books/_search
{
    "query":{
        "bool":{
            "must":[
                {
                    "script":{
                        "script":{
                            "inline":"doc['price'].value>80",
                            "lang":"painless"
                        }
                    }
                }
            ]
        }
    }
}
---- 高亮搜索
get books/_search
{
    "query":{
        "match":{
            "title":"javascript"
        }
    },
    "highlight":{
        "fields":{
            "title":{
                "pre_tags":["<strong>"],
                "post_tags":["</strong>"]
            }
        }
    }
}
---- 多字段高亮 将 require_field_match 设为 false
get books/_search
{
    "query":{
        "match":{"title":"javascript"}
    },
    "highlight":{
        "require_field_match":false,
        "fields":{
            "title":{},
            "description":{}
        }
    }
}
---- 高亮性能分析
---- 默认的 highlighter 高亮器,不需要额外的存储空间,需要对_source做二次分析
---- postings-highlighter 不需要二次分析,但是需要在字段映射中配置 index_options为 offsets.
        即保存关键字偏移量
---- fast-vector-highlighter 速度最快,但也最占用空间,需要在 index_options为 with_position_offsets
        即储存关键字的位置和偏移量
put example/
{
    "mapping":{
        "doc":{
            "properties":{
                "comment":{
                    "type":"text",
                    "index_options":"offsets"
                }
            }
        }
    }
}

put example/
{
    "mapping":{
        "doc":{
            "properties":{
                "comment":{
                    "type":"text",
                    "term_vector":"with_positions_offsets"
                }
            }
        }
    }
}
---- 默认排序 默认以评分降序
get books/_search
{
    "query":{
        "term":{"title":"java"}
    },
    "sort":{"_score":"desc"}
}
---- 多字段排序
get books/_search
{
    "sort":[
        {"price":{"order":"desc"}},
        {"year":{"order":"asc"}},
    ]
}
---- 分片影响评分
---- 5.4之后 text默认采用BM25评分模型.而不是基于tf-idf空间向量模型.
---- 评分模型的选择可以通过 similarity参数在映射中指定
---- 并且es的评分是在每一片分片单独打分的,分片的数量会影响
---- 建立products索引下product类型的name字段,数据类型为text,分词器为ik_smart,评分模型为tf-idf,索引分片数量为1
put products
{
    "settings":{
        "number_of_shards":1
    },
    "mappings":{
        "product":{
            "properties":{
                "name":{
                    "type":"text",
                    "analyzer":"ik_smart",
                    "similarity":"classic"
                }
            }
        }
    }
}
put products/product/1
{
    "name":"柠檬"
}
put products/product/2
{
    "name":"柠檬汽水"
}
put products/product/3
{
    "name":"饮料"
}
----搜索
get products/product
{
    "query":{
        "match":{
            "name":"柠檬"
        }
    }
}

--聚合分析
---- max min avg sum
---- cardinality 类似于sql的distinct计数
---- stats 一次返回 count,max,min,avg,sum 五个指标
---- grades_stats 比stats多了平方和,方差,平均差等
---- percentiles  百分位统计
---- value_count  计算文档的数量
get books/_search
{
    "size":0,
    "aggs":{
        "max_price":{
            "max":{"field":"price"}
        }
    }
}
get books/_search
{
    "aggs":{
        "book_price":{
            "percentiles":{
                "field":"price"
            }
        }
    }
}
get books/_search
{
    "size":0,
    "aggs":{
        "doc_count":{
            "value_count":{
                "field":"author"
            }
        }
    }
}
-- 桶聚合
---- terms aggregation 用于分组聚合
---- 根据language字段聚合,并统计各编程语言的书籍数量
get books/_search
{
    "aggs":{
        "per_count":{
            "terms":{
                "field":"language"
            }
        }
    }
}
---- 在terms aggregation基础之上还可以做指标聚合.例如想统计每一类书的平均价格,可以按照language字段terms aggregation聚合,z再进行 avg aggregation
get books/_search
{
    "aggs":{
        "per_count":{
            "terms":{"field":"language"},
            "aggs":{
                "avg_price":{
                    "avg":{"field":"price"}
                }
            }
        }
    }
}
---- filter aggregation 过滤器聚合.可以把符合条件的文档分到一个桶中
---- 统计title字段包含java的文档的平均价格
get books/_search
{
    "aggs":{
        "java_filter_price":{
            "filter":{
                "term":{"title":"java"}
            },
            "aggs":{
                "avg_price":{
                    "avg":{"field":"price"}
                }
            }
        }
    }
}
---- filters aggregation 多值过滤器.可以按照多个过滤条件将文档放入到不同的桶中
---- 对每个query分组后进行分组统计
get books/_search
{
    "aggs":{
        "per_avg_price":{
            "filters":{
                "filters":[
                    {"match":{"title":"java"}},
                    {"match":{"title":"python"}}
                ]
            },
            "aggs":{
                "avg_price":{
                    "avg":{"field":"price"}
                }
            }
        }
    }
}
---- range aggregation 范围聚合
get books/_search
{
    "aggs":{
        "price_range":{
            "range":{
                "field":"price",
                "ranges":[
                    {"to":50},
                    {"from":50,"to":80},
                    {"from":80}
                ]
            }
        }
    }
}
---- range aggregation 不止可以在数值字段,也可以在日期字段
get books/_search
{
    "aggs":{
        "data_range":{
            "range":{
                "field":"publish_time",
                "format":"yyyy-mm-dd",
                "ranges":[
                    {"to":"2013-09-01"},
                    {"from":"2013-09-01","to":"2014-09-01"},
                    {"from":"2014-09-01"}
                ]
            }
        }
    }
}
---- date range 与 range 的区别在于区间可以使用表达式
get books/_search
{
    "aggs":{
        "my_date_range":{
            "date_range":{
                "field":"publish_time",
                "ranges":[
                    {"to":"now-24M/M"},
                    {"from":"now-24M/M"}
                ]
            }
        }
    }
}

--cat api
---- 索引别名
get /_cat/aliases?v
---- 索引分片数量以及占用空间大小
get /_cat/allocation?v
---- 查看整个集群文档数量或者某个索引文档数量
get /_cat/count?v
get /_cat/count/books?v
---- 查看当前集群中每个数据节点被 fielddata 所使用的堆内存大小
get /_cat/fielddata?v
---- 查看集群健康
get /_cat/health/?v
---- 查看索引信息  健康值 分片数量 副本数量 文档数量 占用空间等等
get /_cat/indices?v
get /_cat/indices/books?v
---- 查看master节点信息
get /_cat/master?v

--cluster api
---- 当前集群健康信息
get /_cluster/health
---- 集群信息
get /_cluster/state
---- 集群统计
get /_cluster/stats